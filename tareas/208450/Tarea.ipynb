{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea: Web Scraping con Selenium y Docker\n",
    "### Objetivo:\n",
    "\n",
    "Aprender a utilizar Selenium junto con Docker para realizar web scraping y extraer información de una página web. En esta tarea, extraerás los títulos de noticias de una página web de tu elección o la proporcionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código de Web Scraping\n",
    "\n",
    "## Ejercico 1:\n",
    "A continuación, te proporciono un script en Python utilizando Selenium para obtener los títulos de noticias de una página web. En este caso, utilizaremos la página de noticias de \"https://news.ycombinator.com/\" como ejemplo.\n",
    "\n",
    "Tu debes completar el script.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bringing K/V context quantisation to Ollama (smcleod.net)\n",
      "Genie 2: A large-scale foundation world model (deepmind.google)\n",
      "Message order in Matrix:, we are deliberately inconsistent (artificialworlds.net)\n",
      "Sitters and Standers (pudding.cool)\n",
      "They don't make them like that any more: the Yamaha DX7 keyboard (kevinboone.me)\n",
      "AI helps researchers dig through old maps to find lost oil and gas wells (lbl.gov)\n",
      "Show HN: Outerbase Studio – Open-Source Database GUI (github.com/outerbase)\n",
      "C64 Basic Tutorial: Using String Manipulation to Write a Text Adventure (retrogamecoders.com)\n",
      "Native dual-range input (muffinman.io)\n",
      "The story of Rogue (spillhistorie.no)\n",
      "WASM-4: Build retro games using WebAssembly for a fantasy console (wasm4.org)\n",
      "Show HN: I combined spaced repetition with emails so you can remember anything (ginkgonotes.com)\n",
      "Deploying Containers on NixOS: A Guide (bkiran.com)\n",
      "My son (9 yrs old) used plain JavaScript to make a game, and wants your feedback (armaansahni.com)\n",
      "Why America's economy is soaring ahead of its rivals (ft.com)\n",
      "AggiesBCI – brain-controlled wheelchair converts thoughts to real-world movement (yusiali.com)\n",
      "Speeding up Ruby by rewriting C in Ruby (jpcamara.com)\n",
      "VectorChord: Store 400k Vectors for $1 in PostgreSQL (pgvecto.rs)\n",
      "IMG_0001 (walzr.com)\n",
      "Launch HN: Parsagon (YC W21) – AI for public affairs and government relations\n",
      "Certificate Authorities and the Fragility of Internet Safety (azeemba.com)\n",
      "The Hoare Cube (johnwickerson.wordpress.com)\n",
      "Show HN: A 5th order motion planner with PH spline blending, written in Ada (prunt-docs.pages.dev)\n",
      "How Typing Transformed Nietzsche's Consciousness (mitpress.mit.edu)\n",
      "Test Driven Development (TDD) for your LLMs? Yes please, more of that please (helix.ml)\n",
      "Bringing the Instructions to the Data (mattpo.pe)\n",
      "Contribution of childhood lead exposure to psychopathology in the US (wiley.com)\n",
      "History of rat control in Alberta (alberta.ca)\n",
      "Ashby (YC W19) Is Hiring Principal Platform Engineers (ashbyhq.com)\n",
      "Interview with Dr. Ken Iverson (1982) (arraycast.com)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://localhost:4444/wd/hub\", # Me conecté localmente al grid de selenium\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Abre la página de noticias \n",
    "driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "# Extrae los títulos de las noticias\n",
    "titles = driver.find_elements(By.CLASS_NAME, \"titleline\")\n",
    "\n",
    "# Imprime los títulos\n",
    "for title in titles:\n",
    "    print(title.text)\n",
    "\n",
    "# Cierra el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción del Código:\n",
    "\n",
    "* Configuración de Selenium: Se configura Selenium con el navegador Chrome utilizando opciones específicas para ejecutarlo dentro de Docker.\n",
    "\n",
    "* Acceso a la Página Web: El script se conecta a la página de noticias de \"YCombinator\" y carga el contenido.\n",
    "\n",
    "* Extracción de Datos: Se utiliza find_elements con la clase storylink para obtener todos los títulos de las noticias en la página.\n",
    "\n",
    "* Impresión de Resultados: Los títulos extraídos se imprimen en la consola."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me conecté localmente para facilitar, uso el Grid de Selenium en el localhost (con Docker). Igualmente, cambié el `CLASS_NAME` a `\"titleline\"` para que si obruviera los títulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2:\n",
    "\n",
    "* Buscar dentro de la página web alguno de los links de arriba (New, Past, etc) y ponerlo en un df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primero mostramos los subtítulos de los los links de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Text                                          Link\n",
      "0  Hacker News             https://news.ycombinator.com/news\n",
      "1          new           https://news.ycombinator.com/newest\n",
      "2         past            https://news.ycombinator.com/front\n",
      "3     comments      https://news.ycombinator.com/newcomments\n",
      "4          ask              https://news.ycombinator.com/ask\n",
      "5         show             https://news.ycombinator.com/show\n",
      "6         jobs             https://news.ycombinator.com/jobs\n",
      "7       submit           https://news.ycombinator.com/submit\n",
      "8        login  https://news.ycombinator.com/login?goto=news\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "\n",
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid (como ya estás usando)\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://localhost:4444/wd/hub\",  # Conexión a Selenium Grid\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Abre la página de Hacker News\n",
    "driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "# Encuentra los enlaces de navegación superiores\n",
    "nav_links = driver.find_elements(By.CSS_SELECTOR, \"span.pagetop a\")\n",
    "\n",
    "# Crea una lista para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Extrae el texto y el enlace de cada elemento\n",
    "for link in nav_links:\n",
    "    text = link.text.strip()  # El texto visible del enlace\n",
    "    href = link.get_attribute(\"href\")  # La URL del enlace\n",
    "    data.append({\"Text\": text, \"Link\": href})  # Guarda en el formato deseado\n",
    "\n",
    "# Crea un DataFrame con los datos\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Cierra el navegador\n",
    "driver.quit()\n",
    "\n",
    "# Muestra el DataFrame\n",
    "print(df)\n",
    "\n",
    "# Guarda el DataFrame en un archivo CSV\n",
    "df.to_csv(\"nav_links.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luego, en past, hacemos click para entrar a la página y extraemos los datos en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                           IMG_0001   \n",
      "1  A particle physics course for high-school stud...   \n",
      "2      Genie 2: A large-scale foundation world model   \n",
      "3  Glojure: Clojure interpreter hosted on Go, wit...   \n",
      "4             How to grow professional relationships   \n",
      "\n",
      "                                          Title Link                  Author  \\\n",
      "0                        https://walzr.com/IMG_0001/               walzr.com   \n",
      "1                           https://ppc.web.cern.ch/                 cern.ch   \n",
      "2  https://deepmind.google/discover/blog/genie-2-...         deepmind.google   \n",
      "3             https://github.com/glojurelang/glojure  github.com/glojurelang   \n",
      "4  https://tej.as/blog/how-to-grow-professional-r...                  tej.as   \n",
      "\n",
      "                                         Author Link  \n",
      "0   https://news.ycombinator.com/from?site=walzr.com  \n",
      "1     https://news.ycombinator.com/from?site=cern.ch  \n",
      "2  https://news.ycombinator.com/from?site=deepmin...  \n",
      "3  https://news.ycombinator.com/from?site=github....  \n",
      "4      https://news.ycombinator.com/from?site=tej.as  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://localhost:4444/wd/hub\",  # Conexión a Selenium Grid\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Abre la página de Hacker News\n",
    "driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "# Haz clic en el enlace \"Past\"\n",
    "past_link = driver.find_element(By.LINK_TEXT, \"past\")\n",
    "past_link.click()\n",
    "\n",
    "# Pausa breve para asegurar que la página cargue completamente\n",
    "time.sleep(3)\n",
    "\n",
    "# Encuentra las filas principales con los datos de las noticias\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"tr.athing\")\n",
    "\n",
    "# Lista para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Itera sobre cada fila para extraer información\n",
    "for row in rows:\n",
    "    try:\n",
    "        # Encuentra el título y su enlace\n",
    "        title_element = row.find_element(By.CSS_SELECTOR, \"span.titleline a\")\n",
    "        title_text = title_element.text.strip()\n",
    "        title_link = title_element.get_attribute(\"href\")\n",
    "\n",
    "        # Intenta encontrar el autor y su enlace (si existe)\n",
    "        try:\n",
    "            author_element = row.find_element(By.CSS_SELECTOR, \"span.sitestr\")\n",
    "            author_text = author_element.text.strip()\n",
    "            author_link = author_element.find_element(By.XPATH, \"..\").get_attribute(\"href\")\n",
    "        except Exception:\n",
    "            author_text = \"N/A\"\n",
    "            author_link = \"N/A\"\n",
    "\n",
    "        # Agrega los datos a la lista\n",
    "        data.append({\n",
    "            \"Title\": title_text,\n",
    "            \"Title Link\": title_link,\n",
    "            \"Author\": author_text,\n",
    "            \"Author Link\": author_link\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando una fila: {e}\")\n",
    "\n",
    "# Cierra el navegador\n",
    "driver.quit()\n",
    "\n",
    "# Crea un DataFrame con los datos\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Muestra el DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Guarda el DataFrame en un archivo CSV\n",
    "df.to_csv(\"past_news.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3:\n",
    "\n",
    "* Buscar algo dentro la pagina en el apartado de \"Search\" y ponerlo en un df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  The cats sitting on a fence in early builds of...   \n",
      "1                               Programming for Cats   \n",
      "2                                          HTTP Cats   \n",
      "3                                          HTTP Cats   \n",
      "4  Cats learn the names of their friend cats in t...   \n",
      "\n",
      "                                            Link Points           Author  \\\n",
      "0  https://news.ycombinator.com/item?id=30438296    535              luu   \n",
      "1  https://news.ycombinator.com/item?id=26047238    466  tigerlilythecat   \n",
      "2  https://news.ycombinator.com/item?id=31438989    427         peterkos   \n",
      "3  https://news.ycombinator.com/item?id=20283794    408        afshinmeh   \n",
      "4  https://news.ycombinator.com/item?id=31396198    386        michaelwm   \n",
      "\n",
      "     Published Comments  \n",
      "0  3 years ago      157  \n",
      "1  4 years ago      109  \n",
      "2  3 years ago       63  \n",
      "3  5 years ago       74  \n",
      "4  3 years ago      219  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configuración del navegador\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Inicializar WebDriver\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://localhost:4444/wd/hub\",\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Abrir la página de Hacker News\n",
    "driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "# Buscar \"cats\" usando el cuadro de búsqueda\n",
    "search_box = driver.find_element(By.XPATH, \"//input[@name='q']\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(\"cats\")\n",
    "search_box.submit()\n",
    "\n",
    "# Esperar a que se carguen los resultados\n",
    "time.sleep(3)\n",
    "\n",
    "# Inicializar estructura para almacenar los datos\n",
    "data = {\n",
    "    \"Title\": [],\n",
    "    \"Link\": [],\n",
    "    \"Points\": [],\n",
    "    \"Author\": [],\n",
    "    \"Published\": [],\n",
    "    \"Comments\": []\n",
    "}\n",
    "\n",
    "# Extraer las historias basadas en los artículos <article>\n",
    "articles = driver.find_elements(By.XPATH, \"//article[@class='Story']\")\n",
    "\n",
    "for article in articles:\n",
    "    try:\n",
    "        # Localizar el elemento del título y el link\n",
    "        title_element = article.find_element(By.XPATH, \".//div[@class='Story_title']//a\")\n",
    "        title = title_element.text.strip()\n",
    "        link = title_element.get_attribute(\"href\")\n",
    "        \n",
    "        # Metadatos\n",
    "        meta = article.find_element(By.XPATH, \".//div[@class='Story_meta']\")\n",
    "        meta_links = meta.find_elements(By.TAG_NAME, \"a\")\n",
    "        \n",
    "        # Puntos\n",
    "        points = meta_links[0].text.split()[0] if len(meta_links) > 0 else \"0\"\n",
    "        \n",
    "        # Autor\n",
    "        author = meta_links[1].text if len(meta_links) > 1 else \"Unknown\"\n",
    "        \n",
    "        # Hace cuánto se publicó\n",
    "        published = meta_links[2].text if len(meta_links) > 2 else \"Unknown\"\n",
    "        \n",
    "        # Comentarios\n",
    "        comments = meta_links[3].text.split()[0] if len(meta_links) > 3 else \"0\"\n",
    "        \n",
    "        # Agregar los datos al diccionario\n",
    "        data[\"Title\"].append(title)\n",
    "        data[\"Link\"].append(link)\n",
    "        data[\"Points\"].append(points)\n",
    "        data[\"Author\"].append(author)\n",
    "        data[\"Published\"].append(published)\n",
    "        data[\"Comments\"].append(comments)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando un artículo: {e}\")\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el DataFrame como archivo CSV\n",
    "df.to_csv(\"hacker_news_cats_with_metadata.csv\", index=False)\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución del Script:\n",
    "    \n",
    "Para ejecutar el script, asegúrate de que los contenedores de Docker estén corriendo y luego ejecuta el siguiente comando en la terminal:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker-compose run --rm python python script.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTREGABLES: \n",
    "* script.py: El archivo con el código para realizar el web scraping y extraer los títulos de las noticias.\n",
    "* README.md: Instrucciones para ejecutar el proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mi entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi entrega se divide en los dos entregables, el script lo hice como un notebook (este notebook) que contiene el código para el web scrapping de los tres ejercicios y el README.md tiene las instrucciones para ejecutar el proyecto y la explicación del proyecto. Ambos documentos están en la carpeta 208450 (mi cu)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
